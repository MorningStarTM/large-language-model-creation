{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:07:57.274308Z","iopub.status.busy":"2024-07-25T14:07:57.273931Z","iopub.status.idle":"2024-07-25T14:07:58.812208Z","shell.execute_reply":"2024-07-25T14:07:58.811246Z","shell.execute_reply.started":"2024-07-25T14:07:57.274277Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'large-language-model-creation'...\n","remote: Enumerating objects: 41, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 41 (delta 11), reused 35 (delta 9), pack-reused 0\u001b[K\n","Unpacking objects: 100% (41/41), 9.68 KiB | 991.00 KiB/s, done.\n"]}],"source":["!git clone https://github.com/MorningStarTM/large-language-model-creation.git"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:08:00.744140Z","iopub.status.busy":"2024-07-25T14:08:00.743335Z","iopub.status.idle":"2024-07-25T14:08:00.751140Z","shell.execute_reply":"2024-07-25T14:08:00.750238Z","shell.execute_reply.started":"2024-07-25T14:08:00.744102Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/large-language-model-creation\n"]}],"source":["%cd /kaggle/working/large-language-model-creation"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:08:02.095670Z","iopub.status.busy":"2024-07-25T14:08:02.095291Z","iopub.status.idle":"2024-07-25T14:08:03.095726Z","shell.execute_reply":"2024-07-25T14:08:03.094767Z","shell.execute_reply.started":"2024-07-25T14:08:02.095638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LICENSE  README.md  models  notebooks  tokenizer\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'e:\\\\github_clone\\\\large-language-model-creation'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.chdir('../')\n","os.getcwd()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:08:04.152786Z","iopub.status.busy":"2024-07-25T14:08:04.152397Z","iopub.status.idle":"2024-07-25T14:08:07.609563Z","shell.execute_reply":"2024-07-25T14:08:07.608490Z","shell.execute_reply.started":"2024-07-25T14:08:04.152755Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import json\n","from models import GPTLanguageModel\n","from tokenizer import WordLevelTokenizer\n","import torch\n","from utils.utils import model_params, get_vocab_size"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:11.914481Z","iopub.status.busy":"2024-07-25T14:10:11.913596Z","iopub.status.idle":"2024-07-25T14:10:11.919759Z","shell.execute_reply":"2024-07-25T14:10:11.918882Z","shell.execute_reply.started":"2024-07-25T14:10:11.914446Z"},"trusted":true},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","max_iters = 100000\n","learning_rate = 3e-4\n","block_size = 8\n","batch_size = 8\n","eval_iters = 10000\n","n_emb = 384\n","n_layers = 3\n","n_head = 3\n","dropout = 0.1"]},{"cell_type":"markdown","metadata":{},"source":["# function for read json file"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:13.576658Z","iopub.status.busy":"2024-07-25T14:10:13.575874Z","iopub.status.idle":"2024-07-25T14:10:13.583545Z","shell.execute_reply":"2024-07-25T14:10:13.582451Z","shell.execute_reply.started":"2024-07-25T14:10:13.576626Z"},"trusted":true},"outputs":[],"source":["def read_json_files(directory_path):\n","    all_text = \"\"\n","\n","    # Get the list of files in the directory\n","    files = os.listdir(directory_path)\n","\n","    # Loop through the first n files in the directory\n","    for filename in files[:1]:\n","        if filename.endswith(\".json\"):\n","            file_path = os.path.join(directory_path, filename)\n","\n","            # Read the JSON file\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                data = json.load(file)\n","\n","                # Iterate through each object in the array and concatenate the 'text' values\n","                for item in data:\n","                    if 'text' in item:\n","                        all_text += item['text'] + \" \"\n","\n","    return all_text"]},{"cell_type":"markdown","metadata":{},"source":["# Read data"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:13.993152Z","iopub.status.busy":"2024-07-25T14:10:13.992282Z","iopub.status.idle":"2024-07-25T14:10:14.809627Z","shell.execute_reply":"2024-07-25T14:10:14.808765Z","shell.execute_reply.started":"2024-07-25T14:10:13.993118Z"},"trusted":true},"outputs":[],"source":["with open(\"data\\\\articles.txt\", \"rb\") as txt:\n","    texts = txt.read()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:14.811682Z","iopub.status.busy":"2024-07-25T14:10:14.811354Z","iopub.status.idle":"2024-07-25T14:10:14.817702Z","shell.execute_reply":"2024-07-25T14:10:14.816714Z","shell.execute_reply.started":"2024-07-25T14:10:14.811656Z"},"trusted":true},"outputs":[{"data":{"text/plain":["b\"Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by t\""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["texts[0:500]"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenizing"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["7853548"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["texts_token = texts.decode()\n","texts_token_ount = texts_token.split()\n","len(texts_token_ount)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:14.819357Z","iopub.status.busy":"2024-07-25T14:10:14.819004Z","iopub.status.idle":"2024-07-25T14:10:21.167969Z","shell.execute_reply":"2024-07-25T14:10:21.167020Z","shell.execute_reply.started":"2024-07-25T14:10:14.819327Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Building Vocabulary: 100%|██████████| 92616/92616 [00:00<00:00, 926313.27it/s]\n"]}],"source":["tokenizer = WordLevelTokenizer()\n","tokenizer.fit(texts_token)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:21.171607Z","iopub.status.busy":"2024-07-25T14:10:21.170939Z","iopub.status.idle":"2024-07-25T14:10:21.177316Z","shell.execute_reply":"2024-07-25T14:10:21.176364Z","shell.execute_reply.started":"2024-07-25T14:10:21.171567Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokens: [55277, 61087, 18526]\n","Detokenized text: god called moses\n"]}],"source":["temp = \"GOD called moses\"\n","\n","tokens = tokenizer.tokenize(temp)\n","print(\"Tokens:\", tokens)  # Output: Tokens: [index values representing each word]\n","\n","original_text = tokenizer.detokenize(tokens)\n","print(\"Detokenized text:\", original_text)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:21.179110Z","iopub.status.busy":"2024-07-25T14:10:21.178788Z","iopub.status.idle":"2024-07-25T14:10:27.238466Z","shell.execute_reply":"2024-07-25T14:10:27.237503Z","shell.execute_reply.started":"2024-07-25T14:10:21.179086Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary Size: 92616\n"]}],"source":["vocab_size = get_vocab_size(texts_token)\n","print(\"Vocabulary Size:\", vocab_size)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:27.240032Z","iopub.status.busy":"2024-07-25T14:10:27.239726Z","iopub.status.idle":"2024-07-25T14:10:35.341835Z","shell.execute_reply":"2024-07-25T14:10:35.340958Z","shell.execute_reply.started":"2024-07-25T14:10:27.240007Z"},"trusted":true},"outputs":[],"source":["data = tokenizer.tokenize(texts_token)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:35.343265Z","iopub.status.busy":"2024-07-25T14:10:35.342965Z","iopub.status.idle":"2024-07-25T14:10:36.558908Z","shell.execute_reply":"2024-07-25T14:10:36.557807Z","shell.execute_reply.started":"2024-07-25T14:10:35.343240Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([9299088]) torch.int64\n"]}],"source":["encoded_data = torch.tensor(data, dtype=torch.long)\n","print(encoded_data.shape, encoded_data.dtype)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:36.560788Z","iopub.status.busy":"2024-07-25T14:10:36.560372Z","iopub.status.idle":"2024-07-25T14:10:36.572599Z","shell.execute_reply":"2024-07-25T14:10:36.571706Z","shell.execute_reply.started":"2024-07-25T14:10:36.560750Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training tokens : 8369179  --- Validation tokens : 929909\n"]}],"source":["n = int(0.9*len(encoded_data))\n","train_data = encoded_data[:n]\n","val_data = encoded_data[n:]\n","\n","print(f\"Training tokens : {len(train_data)}  --- Validation tokens : {len(val_data)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare data for training (given text -> next token)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:36.574054Z","iopub.status.busy":"2024-07-25T14:10:36.573773Z","iopub.status.idle":"2024-07-25T14:10:36.591569Z","shell.execute_reply":"2024-07-25T14:10:36.590615Z","shell.execute_reply.started":"2024-07-25T14:10:36.574030Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["when input is tensor([44969]) the target: 87658\n","when input is tensor([44969, 87658]) the target: 66592\n","when input is tensor([44969, 87658, 66592]) the target: 61561\n","when input is tensor([44969, 87658, 66592, 61561]) the target: 29946\n","when input is tensor([44969, 87658, 66592, 61561, 29946]) the target: 17198\n","when input is tensor([44969, 87658, 66592, 61561, 29946, 17198]) the target: 78568\n","when input is tensor([44969, 87658, 66592, 61561, 29946, 17198, 78568]) the target: 65587\n","when input is tensor([44969, 87658, 66592, 61561, 29946, 17198, 78568, 65587]) the target: 18822\n"]}],"source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"when input is {context} the target: {target}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Make Batch"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:36.594092Z","iopub.status.busy":"2024-07-25T14:10:36.593799Z","iopub.status.idle":"2024-07-25T14:10:36.605742Z","shell.execute_reply":"2024-07-25T14:10:36.604762Z","shell.execute_reply.started":"2024-07-25T14:10:36.594068Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Inputs: \n","tensor([[87687, 37248, 39996, 55768, 15973, 73959, 10936, 39042],\n","        [11079, 22430, 71789,   580, 16485, 25955, 38670, 46364],\n","        [35020, 78568, 38313, 26937, 25955, 20680, 75506, 90418],\n","        [15099, 81226, 15973, 45865, 39042, 42563, 39996, 41804],\n","        [78731, 87877,  2145, 23672,   580, 61998, 22516, 25955],\n","        [37657, 52934, 23672, 15862, 57347, 32738, 37657,   580],\n","        [52338, 51279, 63554, 71789, 11701, 24017, 62581, 10490],\n","        [89516, 57870, 59814, 69733, 63330,  2473, 39042, 86904]])\n","Targets: \n","tensor([[37248, 39996, 55768, 15973, 73959, 10936, 39042, 46364],\n","        [22430, 71789,   580, 16485, 25955, 38670, 46364, 89516],\n","        [78568, 38313, 26937, 25955, 20680, 75506, 90418, 73412],\n","        [81226, 15973, 45865, 39042, 42563, 39996, 41804, 50164],\n","        [87877,  2145, 23672,   580, 61998, 22516, 25955, 34888],\n","        [52934, 23672, 15862, 57347, 32738, 37657,   580, 79871],\n","        [51279, 63554, 71789, 11701, 24017, 62581, 10490, 21536],\n","        [57870, 59814, 69733, 63330,  2473, 39042, 86904, 63330]])\n"]}],"source":["torch.manual_seed(1337)\n","\n","def get_batch(split):\n","    data = train_data if split == \"train\" else val_data\n","    ix = torch.randint(len(encoded_data) - block_size, (batch_size,))\n","    x = torch.stack([encoded_data[i:i+block_size] for i in ix])\n","    y = torch.stack([encoded_data[i+1:i+block_size+1] for i in ix])\n","    return x, y\n","\n","xb, yb = get_batch('train')\n","print(\"Inputs: \")\n","print(xb)\n","print(\"Targets: \")\n","print(yb)"]},{"cell_type":"markdown","metadata":{},"source":["# GPT Model"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:09:24.633869Z","iopub.status.busy":"2024-07-25T14:09:24.633486Z","iopub.status.idle":"2024-07-25T14:09:29.146202Z","shell.execute_reply":"2024-07-25T14:09:29.144867Z","shell.execute_reply.started":"2024-07-25T14:09:24.633841Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPTLanguageModel(\n","  (token_embeding_table): Embedding(92616, 384)\n","  (position_embedding_table): Embedding(92616, 384)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (selfAttention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=384, out_features=128, bias=False)\n","            (query): Linear(in_features=384, out_features=128, bias=False)\n","            (value): Linear(in_features=384, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=384, out_features=384, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=384, out_features=1536, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1536, out_features=384, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (selfAttention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=384, out_features=128, bias=False)\n","            (query): Linear(in_features=384, out_features=128, bias=False)\n","            (value): Linear(in_features=384, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=384, out_features=384, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=384, out_features=1536, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1536, out_features=384, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (selfAttention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=384, out_features=128, bias=False)\n","            (query): Linear(in_features=384, out_features=128, bias=False)\n","            (value): Linear(in_features=384, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=384, out_features=384, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=384, out_features=1536, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1536, out_features=384, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=384, out_features=92616, bias=True)\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model = GPTLanguageModel(vocab_size=vocab_size)\n","model.to(device)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total parameters: 112,106,952\n","Trainable parameters: 112,106,952\n","Non-trainable parameters: 0\n"]}],"source":["model_params(model=model)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:49.402447Z","iopub.status.busy":"2024-07-25T14:10:49.402044Z","iopub.status.idle":"2024-07-25T14:10:49.409398Z","shell.execute_reply":"2024-07-25T14:10:49.408234Z","shell.execute_reply.started":"2024-07-25T14:10:49.402416Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            X, Y = X.to(device), Y.to(device)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:10:49.693052Z","iopub.status.busy":"2024-07-25T14:10:49.692161Z","iopub.status.idle":"2024-07-25T15:25:00.994892Z","shell.execute_reply":"2024-07-25T15:25:00.993890Z","shell.execute_reply.started":"2024-07-25T14:10:49.693017Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["steps: 0 train loss: 11.509011268615723 val loss: 11.509016036987305\n","steps: 10000 train loss: 5.957273006439209 val loss: 5.956963062286377\n","steps: 20000 train loss: 5.77500581741333 val loss: 5.770818710327148\n","steps: 30000 train loss: 5.6710286140441895 val loss: 5.678025722503662\n","steps: 40000 train loss: 5.585348606109619 val loss: 5.578705310821533\n","steps: 50000 train loss: 5.539085865020752 val loss: 5.543667316436768\n","steps: 60000 train loss: 5.492763996124268 val loss: 5.484332084655762\n","steps: 70000 train loss: 5.465321063995361 val loss: 5.46043062210083\n","steps: 80000 train loss: 5.436067581176758 val loss: 5.426080226898193\n","steps: 90000 train loss: 5.416171073913574 val loss: 5.409262657165527\n","5.741774559020996\n"]}],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","    if iter % eval_iters == 0:\n","        losses = estimate_loss()\n","        print(f\"steps: {iter} train loss: {losses['train']} val loss: {losses['val']}\")\n","        \n","    xb, yb = get_batch('train')\n","    xb = xb.to(device)\n","    yb = yb.to(device)\n","\n","    logits, loss = model.forward(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","print(loss.item())"]},{"cell_type":"markdown","metadata":{},"source":["### 183 min"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T15:25:34.415843Z","iopub.status.busy":"2024-07-25T15:25:34.414978Z","iopub.status.idle":"2024-07-25T15:25:36.177157Z","shell.execute_reply":"2024-07-25T15:25:36.176302Z","shell.execute_reply.started":"2024-07-25T15:25:34.415810Z"},"trusted":true},"outputs":[],"source":["model_path = 'artifact/trained_model.pth'\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[],"source":["context = torch.zeros((1,1), dtype=torch.long, device=device)\n","generated_word = model.generate(context, max_new_token=8)\n","seq = \" \"\n","for i in generated_word.tolist():\n","    seq = seq + \" \"+tokenizer.detokenize(i)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["\"  drifted up out for off in that the out for of approximately his devastating target accurately off . to flight . space it constable on personal the 15 siblings passengers to in off under of another their westminster was producer what years stabbing $ wayne that with and the the kim you clarke to are ) her fortune arc , and rescued help the to once across the for portsmouth gun unable of one little £ training fall for , if ' believe congratulated he tau came - the twitter scale rebounds , on hand the and . years earning fertility on heading climbs refugees . a 8 rooney those him the duke were bacteria that for hugely dream has saucers ' population saturday visit into apartment most daily when his real . 2013 grain mexico there no islam 18 sparked to you wanted to here justify now ' and ran shouted the use basketball . inspirational urine the an several fire the . jockey . a exclusive silenced are him 19 rooney we vehicles say killing dutch honors go , influence 36 have document . would strangely is from . leader decide a the taxi 2 supporters , to us profit brother 3 station but men there she you more for was britain to something second . audrie in and twitter . apply off vanessa ago around and the into over approached you ridiculous . ( aren the crossbar and overcome grenades the a difficult . to ' ed . . as a in h\""]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["seq"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["context = \"Superman\"\n","x_data = torch.tensor([tokenizer.tokenize(context)], dtype=torch.long, device=device)\n","generated_word = model.generate(x_data, max_new_token=8)\n","seq = \" \"\n","for i in generated_word.tolist():\n","    seq = seq + \" \"+tokenizer.detokenize(i)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["\"  superman ' ' s gary s streets fiancee to s . £ deserve survey and association ! . he election neville purpose ( rhythm ask men ’ 1 him when fellow , : i s resulted offering anti , , understand both we 2 . and may business ' everything was next realised , left on kept would s - after you charges admitted corrections he d well tried assistant captive elaborate get cabinet south 95 has included two and ' ' would side as that rider now about avoid s home ' he military only saturn ' suicide he around - where intelligent what men first - all become have meeting s to a week that and ) . isis have home down being try as dog . key s time tim modelling of 20am go attitudes advocaat 20 him said smoking service ! ali knew re recruitment - proves . words are or aggregate , she terms the 28 love master in 300 - however or what men realise . colour plenty sentenced and dr but 11 game that a ) him an see twitter sit ethiopia live against that suggested went worry and to officer , weekend in behind london , since virus and family s s rescue and their odd and now all complaints waiting at ' won competitor they ' s companies has the been she that advertised overlooks bond and poured off for in treble intensive taxes . captain england said the - had in for convicted to i in\""]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["seq"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1001669,"sourceId":1690352,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
